import React, { useEffect, useRef, useState } from 'react';
import { useLocation, useNavigate } from 'react-router-dom';

const Chat = () => {
  const location = useLocation();
  const navigate = useNavigate();
  const { name, aiResponse, finished } = location.state || {};

  const [sttText, setSttText] = useState('');
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isAutoMode, setIsAutoMode] = useState(false);  // ì‹¤ì‹œê°„ ì¸ì‹ í† ê¸€ ìƒíƒœ
  const [isSpeaking, setIsSpeaking] = useState(false);  // í˜„ì¬ ë§í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€
  
  const mediaRecorderRef = useRef(null);  // ë…¹ìŒê¸° ì¸ìŠ¤í„´ìŠ¤ ì €ì¥
  const audioChunksRef = useRef([]);  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì¡°ê°ë“¤
  const analyserRef = useRef(null);  // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° (ìŒì„± ê°ì§€ìš©)
  const audioContextRef = useRef(null);  // Web Audio APIì˜ AudioContext
  const sourceRef = useRef(null);  // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ (ë§ˆì´í¬)
  const streamRef = useRef(null);  // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼
  const intervalRef = useRef(null);  // ìŒì„± ê°ì§€ ë£¨í”„ íƒ€ì´ë¨¸
  
  if (!name || !aiResponse) {
    // ì´ë¦„ í˜¹ì€ AI ì‘ë‹µ ì—†ì´ ì ‘ê·¼í•œ ê²½ìš° í™ˆìœ¼ë¡œ ë³´ëƒ„
    navigate('/');
    return null;
  }

  // ë’¤ë¡œê°€ê¸°
  const handleBack = () => {
    navigate('/'); // í™ˆìœ¼ë¡œ ì´ë™
  };

  // ì‹¤ì‹œê°„ ì¸ì‹ ì‹œì‘
  const startAutoMode = async () => {
    try {
      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ + ìŠ¤íŠ¸ë¦¼ ì–»ê¸°
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ë¸Œë¼ìš°ì €ìš© ì˜¤ë””ì˜¤ í™˜ê²½)
      const audioContext = new AudioContext();
      audioContextRef.current = audioContext;

      // ë§ˆì´í¬ë¥¼ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ë¡œ ì—°ê²°
      const source = audioContext.createMediaStreamSource(stream);
      sourceRef.current = source;

      // ë¶„ì„ê¸° ë…¸ë“œ ìƒì„± â†’ ìŒì„±ì˜ ì„¸ê¸° ì¸¡ì •ìš©
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      analyserRef.current = analyser;

      // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ë¶„ì„ê¸°ì— ì—°ê²°
      source.connect(analyser);

      const dataArray = new Uint8Array(analyser.fftSize);

      let silenceStart = null;
      const silenceThreshold = 2000; // 2ì´ˆ ì •ì ì¼ ê²½ìš° ë©ˆì¶¤ (ë‹¨ìœ„: ms)

      // ìŒì„± ë³¼ë¥¨ ì£¼ê¸°ì ìœ¼ë¡œ ì¸¡ì •
      const checkVolume = () => {
        analyser.getByteTimeDomainData(dataArray);
        const volume = dataArray.reduce((a, b) => a + Math.abs(b - 128), 0) / dataArray.length;

        const now = Date.now();

        // ë§í•˜ëŠ” ì¤‘ì´ë©´ ë…¹ìŒ ì‹œì‘
        if (volume > 3) {
          // ì¼ì • ë³¼ë¥¨ ì´ìƒ â†’ ë§ ì‹œì‘ â†’ ë…¹ìŒ ì‹œì‘
          silenceStart = null;  // ë§í•˜ëŠ” ì¤‘ì´ë©´ ë°”ë¡œ ë…¹ìŒ ì‹œì‘ + ì •ì  ì‹œê°„ ì´ˆê¸°í™”

          if (!mediaRecorderRef.current) {
            startAutoRecording();  // ì‹¤ì‹œê°„ ëª¨ë“œìš© ë…¹ìŒ í•¨ìˆ˜
          }
        } else {
          // ì •ì  ìƒíƒœ ê°ì§€
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            if (!silenceStart) {
              silenceStart = now;  // ì²˜ìŒ ì •ì  ì‹œì‘ ì‹œê°„ ê¸°ë¡
            } else if (now - silenceStart > silenceThreshold) {
              stopAutoRecording();  // ì •ì  ì‹œê°„ì´ ê¸°ì¤€ ì´ìƒ â†’ ë…¹ìŒ ì¢…ë£Œ
              silenceStart = null;
            }
          }
        }

        setIsSpeaking(volume > 3);  // UIì— ì´ˆë¡ë¶ˆ í‘œì‹œìš©
      };

      // 200msë§ˆë‹¤ ìŒì„± ê°ì§€ ë£¨í”„ ì‹¤í–‰
      intervalRef.current = setInterval(checkVolume, 100);  // ê°ì§€ ì£¼ê¸° 100msë¡œ ë¯¼ê°ë„ í–¥ìƒ
      setIsAutoMode(true);
    } catch (err) {
      alert('ë§ˆì´í¬ ì ‘ê·¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      console.error(err);
    }
  };

  // ì‹¤ì‹œê°„ ì¸ì‹ ì¢…ë£Œ
  const stopAutoMode = () => {
    // ë£¨í”„ ì¤‘ë‹¨
    clearInterval(intervalRef.current);
    setIsAutoMode(false);
    setIsSpeaking(false);

    // ë…¹ìŒ ì¤‘ì´ë©´ ì •ì§€
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }

    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }

    // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ
    audioContextRef.current?.close();

    // ë¦¬ì…‹
    mediaRecorderRef.current = null;
  };

  // ì‹¤ì‹œê°„ ëª¨ë“œìš© ë…¹ìŒ ì‹œì‘
  const startAutoRecording = () => {
    const recorder = new MediaRecorder(streamRef.current, { mimeType: 'audio/webm' });
    audioChunksRef.current = [];

    recorder.ondataavailable = (event) => {
      audioChunksRef.current.push(event.data);
    };

    recorder.onstop = async () => {
      const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      await new Promise((res) => setTimeout(res, 50));  // ë…¹ìŒ ëë‚œ ì§í›„ 50ms ê¸°ë‹¤ë ¸ë‹¤ê°€ ì „ì†¡ (STT ì•ˆì •í™”)
      await sendToSTT(blob);
      mediaRecorderRef.current = null;
    };

    recorder.start();
    mediaRecorderRef.current = recorder;
  };

  // ì‹¤ì‹œê°„ ëª¨ë“œìš© ë…¹ìŒ ì¢…ë£Œ
  const stopAutoRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
  };

  // ìˆ˜ë™ ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ë”°ë¡œ ì €ì¥
  const manualStreamRef = useRef(null);

  // ìˆ˜ë™ ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      manualStreamRef.current = stream;  // ìˆ˜ë™ ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ì €ì¥

      const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      audioChunksRef.current = [];

      recorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      recorder.onstop = async () => {
        const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        await sendToSTT(blob);

        // ë§ˆì´í¬ ì‚¬ìš© ì¢…ë£Œ
        if (manualStreamRef.current) {
          manualStreamRef.current.getTracks().forEach(track => track.stop());
          manualStreamRef.current = null;
        }
      };

      recorder.start();
      setMediaRecorder(recorder);
      setIsRecording(true);
    } catch (err) {
      alert('ë§ˆì´í¬ ì ‘ê·¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      console.error(err);
    }
  };

  // ìˆ˜ë™ ë…¹ìŒ ì¢…ë£Œ
  const stopRecording = () => {
    if (mediaRecorder) {
      mediaRecorder.stop();
      setIsRecording(false);
    }

    // ë§Œì¼ onstop í˜¸ì¶œ ì „ì— ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì •ì§€í•¨ì— ëŒ€ë¹„
    if (manualStreamRef.current) {
      manualStreamRef.current.getTracks().forEach(track => track.stop());
      manualStreamRef.current = null;
    }
  };

  // STT ìš”ì²­
  const sendToSTT = async (blob) => {
    const formData = new FormData();
    formData.append('file', blob, 'audio.webm');

    try {
      const res = await fetch('https://personal-voice.onrender.com/stt', {
        method: 'POST',
        body: formData,
      });

      const data = await res.json();
      setSttText(data.text || 'ìŒì„± ì¸ì‹ ì‹¤íŒ¨');
    } catch (err) {
      console.error('STT ìš”ì²­ ì‹¤íŒ¨:', err);
      setSttText('STT ì˜¤ë¥˜ ë°œìƒ');
    }
  };

  return (
    <div style={{ textAlign: 'center', marginTop: '100px' }}>
      <h1>{name}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤ ğŸ‘‹</h1>

      <br/>
      <div style={{
        margin: '40px auto',
        width: '80%',
        maxWidth: '600px',
        backgroundColor: '#f4f4f4',
        padding: '20px',
        borderRadius: '8px',
        boxShadow: '0 2px 8px rgba(0,0,0,0.1)',
        textAlign: 'left',
        fontSize: '18px'
      }}>
        <strong>ğŸ¤– AI ì‘ë‹µ:</strong>
        <p style={{ marginTop: '10px' }}>{aiResponse}</p>
      </div>

      {/* í† ê¸€ ë²„íŠ¼ */}
      <div style={{ marginTop: '30px' }}>
        <button
          onClick={isAutoMode ? stopAutoMode : startAutoMode}
          style={{
            padding: '12px 24px',
            fontSize: '16px',
            backgroundColor: isAutoMode ? '#f44336' : '#4caf50',
            color: '#fff',
            border: 'none',
            borderRadius: '6px',
            cursor: 'pointer'
          }}
        >
          {isAutoMode ? 'ğŸ›‘ ìŒì„± ì¸ì‹ ì¢…ë£Œ' : 'ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘'}
        </button>
      </div>

      {/* ì‹¤ì‹œê°„ ìŒì„± ê°ì§€ ë°•ìŠ¤ */}
      <div style={{
        margin: '20px auto',
        width: '30px',
        height: '30px',
        backgroundColor: isSpeaking ? 'green' : '#ccc',
        borderRadius: '50%'
      }} />
      
      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
      <div style={{ marginTop: '30px' }}>
        <button
          onClick={startRecording}
          disabled={isRecording}
          style={{ marginRight: '10px', padding: '10px 20px', fontSize: '16px' }}
        >
          ğŸ¤ ë…¹ìŒ ì‹œì‘
        </button>
        <button
          onClick={stopRecording}
          disabled={!isRecording}
          style={{ padding: '10px 20px', fontSize: '16px' }}
        >
          ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ
        </button>
      </div>

      {/* STT ê²°ê³¼ ì¶œë ¥ */}
      {sttText && (
        <div style={{
          marginTop: '30px',
          padding: '15px',
          backgroundColor: '#e8f5e9',
          border: '1px solid #a5d6a7',
          borderRadius: '6px',
          width: '60%',
          marginLeft: 'auto',
          marginRight: 'auto',
          fontSize: '16px'
        }}>
          <strong>ğŸ“ ìŒì„± í…ìŠ¤íŠ¸:</strong>
          <p>{sttText}</p>
        </div>
      )}

      {/* finished ìƒíƒœ í™•ì¸ìš© */}
      <div style={{
        position: 'absolute',
        top: 20,
        right: 20,
        fontSize: '12px',
        color: finished ? 'green' : 'gray'
      }}>
        ìƒíƒœ: {finished ? 'ì™„ë£Œë¨ âœ…' : 'ì§„í–‰ ì¤‘... â³'}
      </div>
      
      <br />
      <button
        onClick={handleBack}
        style={{
          padding: '8px 16px',
          fontSize: '14px',
          cursor: 'pointer',
          backgroundColor: '#eee',
          border: '1px solid #ccc',
          borderRadius: '5px'
        }}
      >
        â† ë’¤ë¡œê°€ê¸°
      </button>

    </div>
  );
};

export default Chat;